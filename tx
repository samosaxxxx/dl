1 - ADAGRAD OPTIMIZER
import numpy as np

# Define the function and its gradients
def f(x, y):
    return x**2 + y**2

def grad_f(x, y):
    return np.array([2 * x, 2 * y])

# Parameters
eta = 0.1  # Learning rate
epsilon = 1e-8  # Convergence threshold
x = -0.1659  # Initial x
y = 0.4406   # Initial y
bounds = [-1, 1]  # Bounds for x and y

# Initialize sum of squared gradients
sum_sq_grad = np.array([0.0, 0.0])

# Iteration counter
iteration = 0
max_iterations = 10000  # Safety limit

while True:
    # Compute gradients
    grad = grad_f(x, y)

    # Update sum of squared gradients
    sum_sq_grad += grad**2

    # Compute adaptive learning rate
    adaptive_lr = eta / (np.sqrt(sum_sq_grad) + epsilon)

    # Update parameters
    x -= adaptive_lr[0] * grad[0]
    y -= adaptive_lr[1] * grad[1]

    # Enforce bounds
    x = np.clip(x, bounds[0], bounds[1])
    y = np.clip(y, bounds[0], bounds[1])

    # Increment iteration
    iteration += 1

    # Print progress at each iteration
    print(f"Iteration {iteration}: x = {x:.8f}, y = {y:.8f}, f(x, y) = {f(x, y):.8f}")

    # Check convergence
    if np.linalg.norm(grad) < epsilon or iteration >= max_iterations:
        break

# Output results
print(f"\nFinal x: {x:.8f}, y: {y:.8f}")
print(f"Function value: {f(x, y):.8f}")
print(f"Total Iterations: {iteration}")

2 - MOMENTUM GRADIENT
import numpy as np

# The objective function
def objective(x, y):
    return x**2.0 + y**2.0

# The derivative of the objective function
def derivative(x, y):
    return np.array([x * 2.0, y * 2.0])

# Gradient descent algorithm with momentum
def momentum_gradient_descent(objective, derivative, x,y, n_iter, learning_rate, momentum):
    # Generate an initial point
    # Initialize the change vector
    changex = 0.0
    changey= 0.0
    # Run the gradient descent
    for i in range(n_iter):
        # Calculate the gradient
        gradient = derivative(x, y)
        # Calculate the new change vector
        new_changex = learning_rate * gradient[0] + momentum * changex
        new_changey = learning_rate * gradient[1] + momentum * changey
        # Update the solution
        x-=new_changex
        y-=new_changey
        # Store the new change
        changex = new_changex
        changey = new_changey
        # Evaluate the candidate point
        # Report progress
        print(x,y)
    return [x, y]

# Seed the pseudo-random number generator
np.random.seed(1)
# Define the range for input
x = -0.1659  # Initial x
y = 0.4406   # Initial y
# Define the total iterations
n_iter = 30
# Define the learning rate
learning_rate = 0.1
# Define the momentum
momentum = 0.3
# Perform the gradient descent search with momentum
best, score = momentum_gradient_descent(objective, derivative, x,y, n_iter, learning_rate, momentum)
print('Done!')
print('f(%s) = %f' % (best, score))

3 - ADAM OPTIMIZER
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
import numpy as np

# Generate some sample data
X = np.array([-1, 0, 1, 2, 3, 4], dtype=float)
Y = np.array([-3, -1, 1, 3, 5, 7], dtype=float)

# Create a simple sequential model
model = Sequential()
model.add(Dense(1, input_dim=1))

# Compile the model with the Adam optimizer
# The learning rate can be tuned
adam = Adam(learning_rate=0.1)
model.compile(loss='mean_squared_error', optimizer=adam)

# Train the model
model.fit(X, Y, epochs=100, verbose=0)

# Make predictions
predictions = model.predict(X)
print("Predictions:", predictions.flatten())

# Print the learned weights
print("Learned weights (w, b):", [layer.get_weights() for layer in model.layers])

4 - RMSPROP(Root Mean Square Propogation)
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import RMSprop
import numpy as np

# Generate some sample data
X = np.array([-1, 0, 1, 2, 3, 4], dtype=float)
Y = np.array([-3, -1, 1, 3, 5, 7], dtype=float)

# Create a simple sequential model
model = Sequential()
model.add(Dense(1, input_dim=1))

# Compile the model with the RMSprop optimizer
# The learning rate can be tuned
rmsprop = RMSprop(learning_rate=0.1)
model.compile(loss='mean_squared_error', optimizer=rmsprop)

# Train the model
model.fit(X, Y, epochs=100, verbose=0)

# Make predictions
predictions = model.predict(X)
print("Predictions:", predictions.flatten())

# Print the learned weights
print("Learned weights (w, b):", [layer.get_weights() for layer in model.layers])

5 - STOCHASTIC GRADIENT DESCENT
import numpy as np

# Define the function and its gradients
def f(x, y):
    return x**2 + y**2

def grad_f(x, y):
    return np.array([2 * x, 2 * y])

# Parameters
eta = 0.1  # Learning rate
epsilon = 1e-8  # Convergence threshold
x = -0.1659  # Initial x
y = 0.4406   # Initial y
bounds = [-1, 1]  # Bounds for x and y

# Iteration counter
iteration = 0
max_iterations = 10000  # Safety limit

while True:
    # Compute gradients
    grad = grad_f(x, y)

    # Update parameters (SGD update)
    x -= eta * grad[0]
    y -= eta * grad[1]

    # Enforce bounds
    x = np.clip(x, bounds[0], bounds[1])
    y = np.clip(y, bounds[0], bounds[1])

    # Increment iteration
    iteration += 1

    # Print progress at each iteration
    print(f"Iteration {iteration}: x = {x:.8f}, y = {y:.8f}, f(x, y) = {f(x, y):.8f}")

    # Check convergence
    if np.linalg.norm(grad) < epsilon or iteration >= max_iterations:
        break

# Output results
print(f"\nFinal x: {x:.8f}, y: {y:.8f}")
print(f"Function value: {f(x, y):.8f}")
print(f"Total Iterations: {iteration}")

6 - NEURAL NETWORK AND XOR
import numpy as np

# Sigmoid activation function
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# Derivative of sigmoid
def sigmoid_derivative(x):
    return x * (1 - x)

# Training data (XOR example)
X = np.array([[0,0],
              [0,1],
              [1,0],
              [1,1]])

y = np.array([[0],
              [1],
              [1],
              [0]])

# Seed for reproducibility
np.random.seed(42)

# Initialize weights and biases
input_layer_size = 2
hidden_layer_size = 4
output_layer_size = 1

W1 = np.random.randn(input_layer_size, hidden_layer_size)
b1 = np.zeros((1, hidden_layer_size))
W2 = np.random.randn(hidden_layer_size, output_layer_size)
b2 = np.zeros((1, output_layer_size))
print(W1)
# Training parameters
learning_rate = 0.1
epochs = 10000

for epoch in range(epochs):
    # Forward pass
    z1 = np.dot(X, W1) + b1
    a1 = sigmoid(z1)
    z2 = np.dot(a1, W2) + b2
    a2 = sigmoid(z2)

    # Loss (mean squared error)
    loss = np.mean((y - a2) ** 2)

    # Backpropagation
    error_output = (a2 - y) * sigmoid_derivative(a2)
    error_hidden = np.dot(error_output, W2.T) * sigmoid_derivative(a1)

    # Update weights and biases
    W2 -= learning_rate * np.dot(a1.T, error_output)
    b2 -= learning_rate * np.sum(error_output, axis=0, keepdims=True)
    W1 -= learning_rate * np.dot(X.T, error_hidden)
    b1 -= learning_rate * np.sum(error_hidden, axis=0, keepdims=True)

    # Print progress
    if epoch % 1000 == 0:
        print(f"Epoch {epoch}, Loss: {loss:.4f}")

# Test predictions
print("Predictions:")
print(a2)
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score

# ===============================
# Sigmoid and derivatives
# ===============================
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

# ===============================
# Training data (XOR)
# ===============================
X = np.array([[0,0],
              [0,1],
              [1,0],
              [1,1]])
y = np.array([[0],
              [1],
              [1],
              [0]])

# Seed for reproducibility
np.random.seed(42)

# ===============================
# Initialize weights and biases
# ===============================
input_layer_size = 2
hidden_layer_size = 4
output_layer_size = 1

W1 = np.random.randn(input_layer_size, hidden_layer_size)
b1 = np.zeros((1, hidden_layer_size))
W2 = np.random.randn(hidden_layer_size, output_layer_size)
b2 = np.zeros((1, output_layer_size))

# Training parameters
learning_rate = 0.1
epochs = 10000
losses = []

# ===============================
# Training loop
# ===============================
for epoch in range(epochs):
    # Forward pass
    z1 = np.dot(X, W1) + b1
    a1 = sigmoid(z1)
    z2 = np.dot(a1, W2) + b2
    a2 = sigmoid(z2)

    # Loss (MSE)
    loss = np.mean((y - a2) ** 2)
    losses.append(loss)

    # Backpropagation
    error_output = (a2 - y) * sigmoid_derivative(a2)
    error_hidden = np.dot(error_output, W2.T) * sigmoid_derivative(a1)

    # Update weights
    W2 -= learning_rate * np.dot(a1.T, error_output)
    b2 -= learning_rate * np.sum(error_output, axis=0, keepdims=True)
    W1 -= learning_rate * np.dot(X.T, error_hidden)
    b1 -= learning_rate * np.sum(error_hidden, axis=0, keepdims=True)

# ===============================
# Evaluation
# ===============================
pred_probs = a2
preds = (pred_probs > 0.5).astype(int)

# Accuracy
acc = accuracy_score(y, preds)
print("Predictions:", preds.flatten())
print("True labels:", y.flatten())
print(f"Accuracy: {acc*100:.2f}%")

# ===============================
# Visualization
# ===============================
# 1. Loss curve
plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(losses, label="Training Loss", color="blue")
plt.xlabel("Epochs")
plt.ylabel("MSE Loss")
plt.title("Loss Convergence")
plt.legend()

# 2. Confusion Matrix
cm = confusion_matrix(y, preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1])
plt.subplot(1,2,2)
disp.plot(cmap=plt.cm.Blues, values_format="d", ax=plt.gca(), colorbar=False)
plt.title("Confusion Matrix")

plt.tight_layout()
plt.show()

FULL INTERGRATED
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.initializers import Zeros, Constant, GlorotUniform, HeNormal
from tensorflow.keras.callbacks import EarlyStopping

tf.config.run_functions_eagerly(True)

# Load and preprocess Iris dataset
iris = load_iris()
X, y = iris.data, iris.target
X = StandardScaler().fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
y_train = tf.keras.utils.to_categorical(y_train, num_classes=3)
y_test = tf.keras.utils.to_categorical(y_test, num_classes=3)

# Define function to create models
def create_model(initializer, optimizer, use_regularization=False):
    model = Sequential()
    model.add(Dense(16, activation="relu", input_shape=(4,), kernel_initializer=initializer))
    if use_regularization:
        model.add(Dropout(0.3))  # Drop neurons randomly
    model.add(Dense(8, activation="relu", kernel_initializer=initializer))
    if use_regularization:
        model.add(Dropout(0.3))
    model.add(Dense(3, activation="softmax", kernel_initializer=initializer))

    model.compile(optimizer=optimizer,
                  loss="categorical_crossentropy",
                  metrics=["accuracy"])
    return model

# Initializers & Optimizers to test
initializers = {
    "Zeros": Zeros(),
    "Constant(0.1)": Constant(0.1),
    "Xavier(Glorot)": GlorotUniform(),
    "HeNormal": HeNormal()
}
optimizers = {
    "SGD": lambda: tf.keras.optimizers.SGD(learning_rate=0.01),
    "Momentum": lambda: tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),
    "Adagrad": lambda: tf.keras.optimizers.Adagrad(learning_rate=0.01),
    "Adam": lambda: tf.keras.optimizers.Adam(learning_rate=0.01),
    "RMSprop": lambda: tf.keras.optimizers.RMSprop(learning_rate=0.01)
}


# Run experiments
results_no_reg, results_reg = {}, {}
es = EarlyStopping(patience=5, restore_best_weights=True)

for init_name, init in initializers.items():
    for opt_name, opt in optimizers.items():
        label = f"{init_name} + {opt_name}"

        # Without regularization
        model = create_model(init, opt(), use_regularization=False)
        history = model.fit(X_train, y_train, epochs=50, batch_size=16,
                            validation_split=0.2, verbose=0, callbacks=[es])
        _, acc = model.evaluate(X_test, y_test, verbose=0)
        results_no_reg[label] = acc

        # With regularization (Dropout + EarlyStopping)
        model = create_model(init, opt(), use_regularization=True)
        history = model.fit(X_train, y_train, epochs=50, batch_size=16,
                            validation_split=0.2, verbose=0, callbacks=[es])
        _, acc = model.evaluate(X_test, y_test, verbose=0)
        results_reg[label] = acc


# Plot comparison
plt.figure(figsize=(14,6))

plt.subplot(1,2,1)
plt.barh(list(results_no_reg.keys()), list(results_no_reg.values()), color="skyblue", edgecolor="black")
plt.title("Test Accuracy (Without Regularization)")
plt.xlabel("Accuracy")

plt.subplot(1,2,2)
plt.barh(list(results_reg.keys()), list(results_reg.values()), color="lightgreen", edgecolor="black")
plt.title("Test Accuracy (With Regularization: Dropout + EarlyStopping)")
plt.xlabel("Accuracy")

plt.tight_layout()
plt.show()

COMPUTATION GRAPH
import networkx as nx
import matplotlib.pyplot as plt

# Define graph
G = nx.DiGraph()

# Nodes (variables and operations)
G.add_node("x", label="x")
G.add_node("y", label="y")
G.add_node("mul", label="*")
G.add_node("const3", label="3")
G.add_node("add1", label="+")
G.add_node("add2", label="+")
G.add_node("z", label="z")

# Edges (flow of computation)
G.add_edges_from([
    ("x", "mul"),
    ("y", "mul"),
    ("mul", "add2"),
    ("y", "add1"),
    ("const3", "add1"),
    ("add1", "add2"),
    ("add2", "z")
])

# Draw
pos = nx.spring_layout(G, seed=42)
labels = nx.get_node_attributes(G, "label")

plt.figure(figsize=(8,6))
nx.draw(G, pos, with_labels=True, labels=labels,
        node_size=2000, node_color="lightblue",
        arrowsize=20, font_size=12, font_weight="bold")
plt.title("Computational Graph: z = (x * y) + (y + 3)")
plt.show()
