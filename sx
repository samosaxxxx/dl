1 - ADAGRAD OPTIMIZER
import numpy as np
# Define the function and its gradients
def f(x, y):
    return x**2 + y**2
def grad_f(x, y):
    return np.array([2 * x, 2 * y])
# Parameters
eta = 0.1  # Learning rate
epsilon = 1e-8  # Convergence threshold
x = -0.1659  # Initial x
y = 0.4406   # Initial y
bounds = [-1, 1]  # Bounds for x and y
# Initialize sum of squared gradients
sum_sq_grad = np.array([0.0, 0.0])
# Iteration counter
iteration = 0
max_iterations = 10000  # Safety limit
while True:
    # Compute gradients
    grad = grad_f(x, y)
    # Update sum of squared gradients
    sum_sq_grad += grad**2
    # Compute adaptive learning rate
    adaptive_lr = eta / (np.sqrt(sum_sq_grad) + epsilon)
    # Update parameters
    x -= adaptive_lr[0] * grad[0]
    y -= adaptive_lr[1] * grad[1]
    # Enforce bounds
    x = np.clip(x, bounds[0], bounds[1])
    y = np.clip(y, bounds[0], bounds[1])
    # Increment iteration
    iteration += 1
    # Print progress at each iteration
    print(f"Iteration {iteration}: x = {x:.8f}, y = {y:.8f}, f(x, y) = {f(x, y):.8f}")
    # Check convergence
    if np.linalg.norm(grad) < epsilon or iteration >= max_iterations:
        break
# Output results
print(f"\nFinal x: {x:.8f}, y: {y:.8f}")
print(f"Function value: {f(x, y):.8f}")
print(f"Total Iterations: {iteration}")

2 - MOMENTUM GRADIENT
import numpy as np
# The objective function
def objective(x, y):
    return x**2.0 + y**2.0
# The derivative of the objective function
def derivative(x, y):
    return np.array([x * 2.0, y * 2.0])
# Gradient descent algorithm with momentum
def momentum_gradient_descent(objective, derivative, bounds, n_iter, learning_rate, momentum):
    # Generate an initial point
    solution = bounds[:, 0] + np.random.rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])
    # Initialize the change vector
    change = 0.0
    # Run the gradient descent
    for i in range(n_iter):
        # Calculate the gradient
        gradient = derivative(solution[0], solution[1])
        # Calculate the new change vector
        new_change = learning_rate * gradient + momentum * change
        # Update the solution
        solution = solution - new_change
        # Store the new change
        change = new_change
        # Evaluate the candidate point
        solution_eval = objective(solution[0], solution[1])
        # Report progress
        print('>%d f(%s) = %.5f' % (i, solution, solution_eval))
    return [solution, solution_eval]
# Seed the pseudo-random number generator
np.random.seed(1)
# Define the range for input
bounds = np.asarray([[-1.0, 1.0], [-1.0, 1.0]])
# Define the total iterations
n_iter = 30
# Define the learning rate
learning_rate = 0.1
# Define the momentum
momentum = 0.3
# Perform the gradient descent search with momentum
best, score = momentum_gradient_descent(objective, derivative, bounds, n_iter, learning_rate, momentum)
print('Done!')
print('f(%s) = %f' % (best, score))

3 - ADAM OPTIMIZER
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
import numpy as np
# Generate some sample data
X = np.array([-1, 0, 1, 2, 3, 4], dtype=float)
Y = np.array([-3, -1, 1, 3, 5, 7], dtype=float)
# Create a simple sequential model
model = Sequential()
model.add(Dense(1, input_dim=1))
# Compile the model with the Adam optimizer
# The learning rate can be tuned
adam = Adam(learning_rate=0.1)
model.compile(loss='mean_squared_error', optimizer=adam)
# Train the model
model.fit(X, Y, epochs=100, verbose=0)
# Make predictions
predictions = model.predict(X)
print("Predictions:", predictions.flatten())
# Print the learned weights
print("Learned weights (w, b):", [layer.get_weights() for layer in model.layers])

4 - RMSPROP(Root Mean Square Propogation)
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import RMSprop
import numpy as np
# Generate some sample data
X = np.array([-1, 0, 1, 2, 3, 4], dtype=float)
Y = np.array([-3, -1, 1, 3, 5, 7], dtype=float)
# Create a simple sequential model
model = Sequential()
model.add(Dense(1, input_dim=1))
# Compile the model with the RMSprop optimizer
# The learning rate can be tuned
rmsprop = RMSprop(learning_rate=0.1)
model.compile(loss='mean_squared_error', optimizer=rmsprop)
# Train the model
model.fit(X, Y, epochs=100, verbose=0)
# Make predictions
predictions = model.predict(X)
print("Predictions:", predictions.flatten())
# Print the learned weights
print("Learned weights (w, b):", [layer.get_weights() for layer in model.layers])

5 - STOCHASTIC GRADIENT DESCENT
import numpy as np
# Define the function and its gradients
def f(x, y):
    return x**2 + y**2
def grad_f(x, y):
    return np.array([2 * x, 2 * y])
# Parameters
eta = 0.1  # Learning rate
epsilon = 1e-8  # Convergence threshold
x = -0.1659  # Initial x
y = 0.4406   # Initial y
bounds = [-1, 1]  # Bounds for x and y
# Iteration counter
iteration = 0
max_iterations = 10000  # Safety limit
while True:
    # Compute gradients
    grad = grad_f(x, y)
    # Update parameters (SGD update)
    x -= eta * grad[0]
    y -= eta * grad[1]
    # Enforce bounds
    x = np.clip(x, bounds[0], bounds[1])
    y = np.clip(y, bounds[0], bounds[1])
    # Increment iteration
    iteration += 1
    # Print progress at each iteration
    print(f"Iteration {iteration}: x = {x:.8f}, y = {y:.8f}, f(x, y) = {f(x, y):.8f}")
    # Check convergence
    if np.linalg.norm(grad) < epsilon or iteration >= max_iterations:
        break
# Output results
print(f"\nFinal x: {x:.8f}, y: {y:.8f}")
print(f"Function value: {f(x, y):.8f}")
print(f"Total Iterations: {iteration}")

6 - NEURAL NETWORK AND XOR
import numpy as np
# Sigmoid activation function
def sigmoid(x):
    return 1 / (1 + np.exp(-x))
# Derivative of sigmoid
def sigmoid_derivative(x):
    return x * (1 - x)
# Training data (XOR example)
X = np.array([[0,0],
              [0,1],
              [1,0],
              [1,1]])
y = np.array([[0],
              [1],
              [1],
              [0]])
# Seed for reproducibility
np.random.seed(42)
# Initialize weights and biases
input_layer_size = 2
hidden_layer_size = 4
output_layer_size = 1
W1 = np.random.randn(input_layer_size, hidden_layer_size)
b1 = np.zeros((1, hidden_layer_size))
W2 = np.random.randn(hidden_layer_size, output_layer_size)
b2 = np.zeros((1, output_layer_size))
# Training parameters
learning_rate = 0.1
epochs = 10000
for epoch in range(epochs):
    # Forward pass
    z1 = np.dot(X, W1) + b1
    a1 = sigmoid(z1)
    z2 = np.dot(a1, W2) + b2
    a2 = sigmoid(z2)
    # Loss (mean squared error)
    loss = np.mean((y - a2) ** 2)
    # Backpropagation
    error_output = (a2 - y) * sigmoid_derivative(a2)
    error_hidden = np.dot(error_output, W2.T) * sigmoid_derivative(a1)
    # Update weights and biases
    W2 -= learning_rate * np.dot(a1.T, error_output)
    b2 -= learning_rate * np.sum(error_output, axis=0, keepdims=True)
    W1 -= learning_rate * np.dot(X.T, error_hidden)
    b1 -= learning_rate * np.sum(error_hidden, axis=0, keepdims=True)
    # Print progress
    if epoch % 1000 == 0:
        print(f"Epoch {epoch}, Loss: {loss:.4f}")
# Test predictions
print("Predictions:")
print(a2)

7 - XOR Multilayer backpropagation
import numpy as np
# ----- Reproducibility -----
np.random.seed(42)
# ----- Data: XOR -----
# Inputs (x1, x2)
X = np.array([
    [0., 0.],
    [0., 1.],
    [1., 0.],
    [1., 1.],
])  # shape: (4,2)
# Targets (x1 XOR x2)
y = np.array([[0.], [1.], [1.], [0.]])  # shape: (4,1)
# ----- Network topology -----
n_input  = 2
n_hidden = 3
n_output = 1
# ----- Parameters (weights & biases) -----
W1 = np.random.randn(n_input,  n_hidden) * 0.5
b1 = np.zeros((1, n_hidden))
W2 = np.random.randn(n_hidden, n_output) * 0.5
b2 = np.zeros((1, n_output))
# ----- Hyperparameters -----
lr     = 0.1     # learning rate
epochs = 10000   # iterations
print_every = 1000
# ----- Activations -----
def sigmoid(z):
    return 1.0 / (1.0 + np.exp(-z))
def dsigmoid(a):
    # derivative wrt pre-activation when provided activation a = sigmoid(z)
    return a * (1.0 - a)
# Binary cross-entropy (stable)
def bce_loss(y_true, y_pred, eps=1e-8):
    y_pred = np.clip(y_pred, eps, 1 - eps)
    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))
# ----- Training Loop -----
for epoch in range(1, epochs + 1):
    # Forward pass
    z1 = X @ W1 + b1          # (4,3)
    a1 = sigmoid(z1)          # hidden
    z2 = a1 @ W2 + b2         # (4,1)
    y_hat = sigmoid(z2)       # output
    # Loss
    loss = bce_loss(y, y_hat)
    # Backpropagation
    # dL/dz2 = (y_hat - y) for BCE + sigmoid output
    dz2 = (y_hat - y)                        # (4,1)
    dW2 = a1.T @ dz2 / len(X)                # (3,1)
    db2 = np.sum(dz2, axis=0, keepdims=True) / len(X)
    # Hidden layer
    da1 = dz2 @ W2.T                         # (4,3)
    dz1 = da1 * dsigmoid(a1)                 # (4,3)
    dW1 = X.T @ dz1 / len(X)                 # (2,3)
    db1 = np.sum(dz1, axis=0, keepdims=True) / len(X)
    # Gradient step
    W2 -= lr * dW2
    b2 -= lr * db2
    W1 -= lr * dW1
    b1 -= lr * db1
    if epoch % print_every == 0:
        preds = (y_hat > 0.5).astype(int)
        acc = np.mean(preds == y)
        print(f"Epoch {epoch:5d} | loss={loss:.6f} | acc={acc:.2f}")
# ----- Final evaluation -----
z1 = X @ W1 + b1
a1 = sigmoid(z1)
z2 = a1 @ W2 + b2
y_hat = sigmoid(z2)
preds = (y_hat > 0.5).astype(int)
print("\nInputs:\n", X)
print("Targets:\n", y.ravel())
print("Predicted probs:\n", y_hat.ravel())
print("Predicted labels:\n", preds.ravel())

8 - XOR MLP â€” With a Library (PyTorch)
# pip install torch  # if you don't have it
import torch
import torch.nn as nn
import torch.optim as optim
# ----- Reproducibility -----
torch.manual_seed(42)
# ----- Data: XOR -----
X = torch.tensor([[0.,0.],[0.,1.],[1.,0.],[1.,1.]], dtype=torch.float32)
y = torch.tensor([[0.],[1.],[1.],[0.]], dtype=torch.float32)
# ----- Model -----
class XORNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(2, 3),
            nn.Sigmoid(),
            nn.Linear(3, 1),
            nn.Sigmoid()
        )
    def forward(self, x):
        return self.net(x)
model = XORNet()
# ----- Loss & Optimizer -----
criterion = nn.BCELoss()
optimizer = optim.SGD(model.parameters(), lr=0.1)
# ----- Train -----
epochs = 5000
for epoch in range(1, epochs + 1):
    optimizer.zero_grad()
    y_hat = model(X)
    loss = criterion(y_hat, y)
    loss.backward()
    optimizer.step()
    if epoch % 500 == 0:
        preds = (y_hat.detach() > 0.5).float()
        acc = (preds == y).float().mean().item()
        print(f"Epoch {epoch:4d} | loss={loss.item():.6f} | acc={acc:.2f}")
# ----- Final evaluation -----
with torch.no_grad():
    y_hat = model(X)
    preds = (y_hat > 0.5).int()
    print("\nInputs:\n", X.numpy())
    print("Targets:\n", y.numpy().ravel())
    print("Predicted probs:\n", y_hat.numpy().ravel())
    print("Predicted labels:\n", preds.numpy().ravel())

8 - Gradient Boosting with a Library (scikit-learn)
from sklearn.ensemble import GradientBoostingClassifier
import numpy as np
X = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([0,1,1,0])
gb = GradientBoostingClassifier(
    n_estimators=10, learning_rate=0.5, max_depth=2  # depth=2
)
gb.fit(X, y)
print("Preds:", gb.predict(X))

9 - Computation Graph
import numpy as np
class Node:
    def __init__(self, value, parents=(), op=""):
        self.value = np.array(value, dtype=float)
        self.parents = parents
        self.op = op
        self.grad = np.zeros_like(self.value)
        self._backward = lambda: None
    def backward(self):
        topo = []
        visited = set()
        def build_topo(node):
            if node not in visited:
                visited.add(node)
                for parent in node.parents:
                    build_topo(parent)
                topo.append(node)
        build_topo(self)
        self.grad = np.ones_like(self.value)  # seed gradient
        for node in reversed(topo):
            node._backward()
    # --- Operator Overloading ---
    def __add__(self, other):
        other = other if isinstance(other, Node) else Node(other)
        return add(self, other)
    def __radd__(self, other):
        return self + other
    def __mul__(self, other):
        other = other if isinstance(other, Node) else Node(other)
        return mul(self, other)
    def __rmul__(self, other):
        return self * other
    def __neg__(self):
        return self * -1.0
    def __sub__(self, other):
        return self + (-other)
    def __rsub__(self, other):
        return other + (-self)
    def __truediv__(self, other):
        other = other if isinstance(other, Node) else Node(other)
        return self * (other ** -1)
    def __pow__(self, power):
        out = Node(self.value ** power, (self,), op=f"pow({power})")
        def _backward():
            self.grad += (power * self.value ** (power - 1)) * out.grad
        out._backward = _backward
        return out
    def __matmul__(self, other):  # matrix multiply
        other = other if isinstance(other, Node) else Node(other)
        out = Node(self.value @ other.value, (self, other), op="matmul")
        def _backward():
            self.grad += out.grad @ other.value.T
            other.grad += self.value.T @ out.grad
        out._backward = _backward
        return out
    def __repr__(self):
        return f"Node(value={self.value}, grad={self.grad}, op={self.op})"
# --- Functions ---
def add(a, b):
    out = Node(a.value + b.value, (a, b), op="add")
    def _backward():
        a.grad += out.grad
        b.grad += out.grad
    out._backward = _backward
    return out
def mul(a, b):
    out = Node(a.value * b.value, (a, b), op="mul")
    def _backward():
        a.grad += b.value * out.grad
        b.grad += a.value * out.grad
    out._backward = _backward
    return out
def log(a):
    out = Node(np.log(a.value), (a,), op="log")
    def _backward():
        a.grad += (1 / a.value) * out.grad
    out._backward = _backward
    return out
def exp(a):
    out = Node(np.exp(a.value), (a,), op="exp")
    def _backward():
        a.grad += out.value * out.grad
    out._backward = _backward
    return out
def sigmoid(a):
    val = 1 / (1 + np.exp(-a.value))
    out = Node(val, (a,), op="sigmoid")
    def _backward():
        a.grad += (val * (1 - val)) * out.grad
    out._backward = _backward
    return out
'''#Simple Equation (x+y)*w
x = Node(2.0)
y = Node(3.0)
w = Node(4.0)
z = mul(add(x, y), w)   # (x+y)*w
z.backward()
print("z =", z.value)
print("dz/dx =", x.grad)  # should be w
print("dz/dy =", y.grad)  # should be w
print("dz/dw =", w.grad)  # should be (x+y)'''
#Logistic Loss
x = Node(1.0)
w = Node(2.0)
y = Node(0.0)
z = x * w
y_hat = sigmoid(z)
loss = -(y * log(y_hat) + (1 - y) * log(1 - y_hat))
loss.backward()
print("Loss =", loss.value)
print("dLoss/dw =", w.grad)





